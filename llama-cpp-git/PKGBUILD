# Maintainer: aur.chaotic.cx

: ${_install_path:=opt}

_pkgname="llama-cpp"
pkgbase="$_pkgname-git"
pkgname=(
  "$_pkgname-git"
  "$_pkgname-x64v3-git"
  "$_pkgname-cuda-git"
)
pkgver=b4966.r1.gf17a3bb
pkgrel=1
pkgdesc="Port of Facebook's LLaMA model in C/C++"
url="https://github.com/ggerganov/llama.cpp"
license=('MIT')
arch=('x86_64')

depends=(
  'curl'
  'python'
  'python-numpy'
  'python-sentencepiece' # AUR
  'openblas'
  'vulkan-icd-loader'
)
makedepends=(
  'cmake'
  'cuda'
  'git'
  'ninja'
  'openmp'
  'patchelf'
  'shaderc'
  'vulkan-headers'
)

_pkgsrc="$_pkgname"
source=(
  "$_pkgsrc"::"git+$url.git"
  "git+https://github.com/nomic-ai/kompute.git"
)
sha256sums=(
  'SKIP'
  'SKIP'
)

prepare() {
  cd "$_pkgsrc"
  git submodule init
  git config submodule.kompute.url "${srcdir}/kompute"
  git -c protocol.file.allow=always submodule update
}

pkgver() {
  cd "$_pkgsrc"
  git describe --long --tags --abbrev=7 --exclude='*[a-zA-Z][a-zA-Z]*' --match='b*' \
    | sed -E 's/([^-]*-g)/r\1/;s/-/./g'
}

build() (
  local _cmake_common=(
    -S "$_pkgsrc"
    -G Ninja
    -DCMAKE_BUILD_TYPE=None
    -DCMAKE_INSTALL_PREFIX="/$_install_path/$_pkgname"
    -DLLAMA_CURL=ON
    -DGGML_NATIVE=OFF
    -DGGML_LTO=ON
    -DGGML_RPC=ON
    -DGGML_ALL_WARNINGS=OFF
    -DGGML_ALL_WARNINGS_3RD_PARTY=OFF
    -DGGML_BLAS=ON
    -DGGML_BLAS_VENDOR=OpenBLAS
    -DGGML_VULKAN=ON
    -DGGML_STATIC=OFF
    -DBUILD_SHARED_LIBS=ON
    -Wno-dev
  )

  local _cmake_x64v1=(
    -DGGML_AVX2=OFF
    -DGGML_AVX=OFF
    -DGGML_BMI2=OFF
    -DGGML_F16C=OFF
    -DGGML_FMA=OFF
  )

  local _cmake_x64v3=(
    -DGGML_AVX2=ON
    -DGGML_AVX=ON
    -DGGML_BMI2=ON
    -DGGML_F16C=ON
    -DGGML_FMA=ON
  )

  local _cmake_cuda=(
    -DGGML_CUDA=ON
    -DGGML_CUDA_F16=ON
  )

  local _build_path

  if grep -Eqm1 '\b'"$_pkgname"'-git\b' <<< "${pkgname[*]}"; then
    echo "Building with OpenBLAS + Vulkan support..."
    _build_path="x64v1"
    cmake -B "build_${_build_path}" "${_cmake_common[@]}" "${_cmake_x64v1[@]}"
    cmake --build "build_${_build_path}"
    DESTDIR="fakeinstall_${_build_path}" cmake --install "build_${_build_path}"
  fi

  if grep -Eqm1 '\b'"$_pkgname"'-x64v3-git\b' <<< "${pkgname[*]}"; then
    echo "Building with OpenBLAS + Vulkan + x86-64-v3 support..."
    _build_path="x64v3"
    cmake -B "build_${_build_path}" "${_cmake_common[@]}" "${_cmake_x64v3[@]}"
    cmake --build "build_${_build_path}"
    DESTDIR="fakeinstall_${_build_path}" cmake --install "build_${_build_path}"
  fi

  if grep -Eqm1 '\b'"$_pkgname"'-cuda-git\b' <<< "${pkgname[*]}"; then
    echo "Building with OpenBLAS + Vulkan + CUDA support..."
    _build_path="cuda"
    cmake -B "build_${_build_path}" "${_cmake_common[@]}" "${_cmake_cuda[@]}"
    cmake --build "build_${_build_path}"
    DESTDIR="fakeinstall_${_build_path}" cmake --install "build_${_build_path}"
  fi

  echo "Deleting unneeded tests..."
  rm -rf fakeinstall_*/$_install_path/$_pkgname/bin/test*
  rm -rf fakeinstall_*/$_install_path/$_pkgname/include
  rm -rf fakeinstall_*/$_install_path/$_pkgname/lib/cmake
  rm -rf fakeinstall_*/$_install_path/$_pkgname/lib/pkgconfig

  local i _files
  _files=(
    fakeinstall_*/$_install_path/$_pkgname/bin/llama-*
    fakeinstall_*/$_install_path/$_pkgname/bin/vulkan-*
    fakeinstall_*/$_install_path/$_pkgname/lib/*.so
  )
  for i in "${_files[@]}"; do
    patchelf --set-rpath '$ORIGIN/../lib' "$i"
  done
)

check() {
  ctest --test-dir build_vulkan_x64v3 --output-on-failure -L 'main|curl' --verbose --timeout 900 || :
}

_package_license() {
  install -Dm644 "$_pkgsrc/LICENSE" -t "$pkgdir/usr/share/licenses/$pkgname/"
  chmod -R u+rwX,go+rX,go-w "$pkgdir/"
}

_package_systemd() {
  install -Dm644 /dev/stdin "$pkgdir/etc/conf.d/$_pkgname" << END
LLAMA_ARGS=""
END

  install -Dm644 /dev/stdin "$pkgdir/usr/lib/systemd/system/$_pkgname.service" << END
[Unit]
Description=$_pkgname Server
After=syslog.target network.target local-fs.target remote-fs.target nss-lookup.target

[Service]
Type=simple
EnvironmentFile=/etc/conf.d/$_pkgname
ExecStart=/$_install_path/$_pkgname/bin/llama-server \$LLAMA_ARGS
ExecReload=/bin/kill -s HUP \$MAINPID
Restart=on-failure

[Install]
WantedBy=multi-user.target
END
}

_package_lamma-cpp() {
  local _base_dir="$1"
  cp --reflink=auto -a "$_base_dir"/* -t "$pkgdir/"

  install -dm755 "$pkgdir/usr/bin"
  ln -srf "$pkgdir/$_install_path/$_pkgname/bin/llama-cli" "$pkgdir/usr/bin/${i##*/}"

  chmod -R u+rwX,go+rX,go-w "$pkgdir/"
}

package_llama-cpp-git() {
  pkgdesc+=" with OpenBLAS + Vulkan optimizations"

  provides=("${_pkgname//-/.}")
  conflicts=("${_pkgname//-/.}")
  replaces=('llama-cpp-vulkan-git')

  backup=("etc/conf.d/$_pkgname")

  _package_lamma-cpp fakeinstall_x64v1

  _package_systemd
  _package_license
}

package_llama-cpp-cuda-git() {
  pkgdesc+=" with OpenBLAS + Vulkan + CUDA optimizations"

  depends+=('cuda')

  provides=("${_pkgname//-/.}")
  conflicts=("${_pkgname//-/.}")

  backup=("etc/conf.d/$_pkgname")

  _package_lamma-cpp fakeinstall_cuda

  _package_systemd
  _package_license
}

package_llama-cpp-x64v3-git() {
  pkgdesc+=" with OpenBLAS + Vulkan + x86-64-v3 optimizations"

  provides=(
    "$_pkgname"
    "${_pkgname//-/.}"
  )
  conflicts=(
    "$_pkgname"
    "${_pkgname//-/.}"
  )
  replaces=('llama-cpp-vulkan-x64v3-git')

  backup=("etc/conf.d/$_pkgname")

  _package_lamma-cpp fakeinstall_x64v3

  _package_systemd
  _package_license
}
