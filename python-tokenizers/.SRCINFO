pkgbase = python-tokenizers
	pkgdesc = Fast State-of-the-Art Tokenizers optimized for Research and Production
	pkgver = 0.21.0
	pkgrel = 1
	url = https://github.com/huggingface/tokenizers
	arch = i686
	arch = x86_64
	license = Apache-2.0
	checkdepends = python-datasets
	checkdepends = python-numpy
	checkdepends = python-pyarrow
	checkdepends = python-pytest
	checkdepends = python-requests
	checkdepends = python-setuptools-rust
	makedepends = clang
	makedepends = rust-bindgen
	makedepends = python-build
	makedepends = python-installer
	makedepends = python-maturin
	makedepends = python-setuptools-rust
	makedepends = python-wheel
	depends = python
	options = !lto
	source = tokenizers-0.21.0.tar.gz::https://github.com/huggingface/tokenizers/archive/refs/tags/v0.21.0.tar.gz
	source = norvig-big.txt::https://norvig.com/big.txt
	source = roberta.json::https://huggingface.co/roberta-large/raw/main/tokenizer.json
	sha256sums = 841279ad797d575ed3cf31fc4f30e09e37acbd35028d30c51fc0879ef7ed4094
	sha256sums = fa066c7d40f0f201ac4144e652aa62430e58a6b3805ec70650f678da5804e87b
	sha256sums = 847bbeab6174d66a88898f729d52fa8d355fafe1bea101cf960dd404581df70e

pkgname = python-tokenizers
